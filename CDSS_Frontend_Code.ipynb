{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index successfully loaded from storage.\n",
      "Successfully createa a query engine\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import chardet\n",
    "import requests\n",
    "import streamlit as st\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "\n",
    "openai_key = ''\n",
    "\n",
    "# Set OpenAI API Key\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "\n",
    "# Specify the storage directory\n",
    "persist_dir = \"/Users/tanmay/Documents/Pro-Projects/CDSS-MIMIC/VectorStore_Indexes\"\n",
    "\n",
    "# Initialize the storage context with the persist_dir\n",
    "storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "\n",
    "# Load the index from the storage context\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "print(\"Index successfully loaded from storage.\")\n",
    "\n",
    "# Create a query engine from the index\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "print(\"Successfully createa a query engine\")\n",
    "\n",
    "\n",
    "def GPT_Input_Preprocessor(user_input):\n",
    "\n",
    "    KEY = openai_key\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    context_text = \"\"\"\n",
    "    You are an expert in structuring patient data for a Clinical Decision Support System (CDSS).\n",
    "    Your task is to extract patient details and organize them into a structured JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {KEY}\"\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": context_text},\n",
    "        {\"role\": \"user\", \"content\": str(user_input)}\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def Generate_JSON_Output(User_Query):\n",
    "\n",
    "  Instructions1 = \"Return all possible information for what is requested along with the information about the subject such as subject_id as Patient ID, gender and age. Make sure you give separate output for different subject_ids.\"\n",
    "\n",
    "  CDSS_Query1 = User_Query + Instructions1\n",
    "  response = query_engine.query(CDSS_Query1)\n",
    "\n",
    "  patients_data = []\n",
    "  patient_json = GPT_Input_Preprocessor(response)\n",
    "  if patient_json:\n",
    "    patients_data.append(patient_json)\n",
    "\n",
    "  return patients_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_Query = \"Which patients had abnormal liver function test results and were diagnosed with hepatic cirrhosis or portal hypertension?\"\n",
    "\n",
    "output = Generate_JSON_Output(User_Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Patient ID': 21636229,\n",
       "   'Gender': 'M',\n",
       "   'Age': 57,\n",
       "   'Abnormal Liver Function Test Results': {'Bilirubin, Total': '1.9 mg/dL',\n",
       "    'Hematocrit': '29.5%'},\n",
       "   'Diagnoses': ['Alcoholic cirrhosis of liver with ascites',\n",
       "    'Portal hypertension']},\n",
       "  {'Patient ID': 20429160,\n",
       "   'Gender': 'M',\n",
       "   'Age': 43,\n",
       "   'Abnormal Liver Function Test Results': {'PT': '16.9 sec',\n",
       "    'Hemoglobin': '9.4 g/dL'},\n",
       "   'Diagnoses': ['Abscess of liver', 'Acute and subacute necrosis of liver']}]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontend UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Delete the file if it exists\n",
    "if os.path.exists('plan3.py'):\n",
    "    os.remove('plan3.py')\n",
    "\n",
    "# Step 2: Write the Streamlit app code to app.py\n",
    "with open('plan3.py', 'w') as f:\n",
    "    f.write('''\n",
    "            \n",
    "import psycopg2\n",
    "import base64\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import streamlit as st\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "# Set OpenAI API Key\n",
    "openai_key = ''\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "\n",
    "# Specify the storage directory\n",
    "persist_dir = \"/Users/tanmay/Documents/Pro-Projects/CDSS-MIMIC/VectorStore_Indexes\"\n",
    "\n",
    "# Initialize the storage context with the persist_dir\n",
    "storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "\n",
    "# Load the index from the storage context\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Create a query engine from the index\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "def GPT_Input_Preprocessor(raw_response):\n",
    "    \"\"\"\n",
    "    Sends the user's input to OpenAI GPT API to preprocess the input.\n",
    "    \"\"\"\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    context_text = \"\"\"\n",
    "    You are an expert in structuring patient data for a Clinical Decision Support System (CDSS).\n",
    "    Your task is to extract patient details and organize them into a structured JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_key}\"\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": context_text},\n",
    "        {\"role\": \"user\", \"content\": str(raw_response)}\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def Generate_JSON_Output(user_query):\n",
    "    \"\"\"\n",
    "    Generates a JSON output based on the user's query and OpenAI API response.\n",
    "    \"\"\"\n",
    "    instructions = \"Return all possible information for what is requested along with the information about the subject such as subject_id as Patient ID, gender, and age. Make sure you give separate output for different subject_ids.\"\n",
    "    cdss_query = user_query + instructions\n",
    "\n",
    "    # Query the index\n",
    "    response = query_engine.query(cdss_query)\n",
    "\n",
    "    # Process the response into structured JSON\n",
    "    if response:\n",
    "        patients_data = []\n",
    "        patient_json = GPT_Input_Preprocessor(response.response)  # Ensure `.response` is accessed properly\n",
    "        if patient_json:\n",
    "            patients_data.append(patient_json)\n",
    "\n",
    "        return patients_data\n",
    "    else:\n",
    "        st.error(\"Failed to retrieve data from the query engine.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "                     \n",
    "# Streamlit UI for Sidebar Navigation\n",
    "\n",
    "st.set_page_config(layout=\"wide\", page_title=\"Clinical Decision Support System (CDSS)\")\n",
    "\n",
    "# Encode the image into base64\n",
    "image_path = \"/Users/tanmay/Documents/Pro-Projects/CDSS-MIMIC/image-med.png\"\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode()\n",
    "\n",
    "# Add CSS for sidebar background\n",
    "sidebar_background = f\"\"\"\n",
    "<style>\n",
    "    [data-testid=\"stSidebar\"] {{\n",
    "        background-image: url(\"data:image/jpeg;base64,{encoded_image}\");\n",
    "        background-size: cover;\n",
    "        background-repeat: no-repeat;\n",
    "        background-position: center;\n",
    "        opacity: 1.0; /* Adjust this value to change opacity */\n",
    "    }}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Inject CSS into Streamlit\n",
    "st.markdown(sidebar_background, unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"ðŸ¥ Clinical Decision Support System (CDSS)\")\n",
    "\n",
    "# Sidebar for query and patient navigation\n",
    "with st.sidebar:\n",
    "    st.header(\"Navigation\")\n",
    "    user_query = st.text_area(\"Enter your query:\", height=150)\n",
    "\n",
    "    if st.button(\"Submit Query\"):\n",
    "        if user_query.strip():\n",
    "            try:\n",
    "                # Ensure the output is a list of patient dictionaries\n",
    "                raw_output = Generate_JSON_Output(user_query)\n",
    "                patients_data = raw_output[0] if isinstance(raw_output, list) and isinstance(raw_output[0], list) else raw_output\n",
    "                st.session_state['patients_data'] = patients_data\n",
    "                st.session_state['current_patient_index'] = 0\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error processing query: {e}\")\n",
    "        else:\n",
    "            st.error(\"Please enter a query.\")\n",
    "\n",
    "# Retrieve patient data from session state\n",
    "patients_data = st.session_state.get('patients_data', [])\n",
    "\n",
    "if isinstance(patients_data, list) and len(patients_data) > 0:\n",
    "    # Sidebar navigation for patients\n",
    "    patient_ids = [p.get(\"Patient ID\", \"Unknown ID\") for p in patients_data if isinstance(p, dict)]\n",
    "    selected_patient_index = st.sidebar.radio(\"Select Patient\", range(len(patient_ids)), \n",
    "                                               format_func=lambda i: f\"Patient {patient_ids[i]}\")\n",
    "    \n",
    "    selected_patient = patients_data[selected_patient_index]\n",
    "\n",
    "    # Main panel to display patient data\n",
    "    st.markdown(\"<h2 style='font-size:20px; font-weight:bold;'>Patient Details</h2>\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Display first three keys in a compact format\n",
    "    patient_id = selected_patient.get(\"Patient ID\", \"Unknown\")\n",
    "    gender = selected_patient.get(\"Gender\", \"Unknown\")\n",
    "    age = selected_patient.get(\"Age\", \"Unknown\")\n",
    "    \n",
    "    # Adjust font size and style of the first three keys\n",
    "    st.markdown(f\"\"\"\n",
    "        <div style=\"font-size:18px; font-weight:bold; margin-bottom:10px;\">\n",
    "            Patient ID: <span style=\"color:green;\">{str(patient_id)}</span><br>\n",
    "            Gender: {gender}<br>\n",
    "            Age: <span style=\"color:green;\">{str(age)}</span>\n",
    "        </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Display remaining data\n",
    "    for key, value in selected_patient.items():\n",
    "        # Skip displaying the first three keys again\n",
    "        if key in [\"Patient ID\", \"Gender\", \"Age\"]:\n",
    "            continue\n",
    "\n",
    "        # Font size and spacing for all keys\n",
    "        st.markdown(f\"<h3 style='font-size:18px; font-weight:bold; margin-bottom:0px;'>{key}:</h3>\", unsafe_allow_html=True)\n",
    "\n",
    "        # Handle list of dictionaries (e.g., Potential Risks)\n",
    "        if isinstance(value, list) and all(isinstance(item, dict) for item in value):\n",
    "            for index, item in enumerate(value, start=1):\n",
    "                st.markdown(f\"#### {key} {index}:\", unsafe_allow_html=True)\n",
    "                for sub_key, sub_value in item.items():\n",
    "                    st.markdown(f\"- **{sub_key}:** {sub_value}\", unsafe_allow_html=True)\n",
    "\n",
    "        # Handle simple lists (e.g., Recommended Next Steps)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                st.markdown(f\"- {item}\", unsafe_allow_html=True)\n",
    "            st.markdown(\"<br>\", unsafe_allow_html=True)\n",
    "\n",
    "        # Handle dictionaries\n",
    "        elif isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                st.markdown(f\"- **{sub_key}:** {sub_value}\", unsafe_allow_html=True)\n",
    "\n",
    "        # Handle scalar values (e.g., plain strings or numbers)\n",
    "        else:\n",
    "            st.markdown(f\"<p style='font-size:16px; margin-bottom:0px;'>{value}</p>\", unsafe_allow_html=True)\n",
    "else:\n",
    "    st.info(\"No valid data to display. Please enter a query.\")\n",
    "''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated process with PID 21122 on port 8501\n",
      "Terminated process with PID 21122 on port 8501\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://10.145.11.157:8501\n",
      "\n",
      "  For better performance, install the Watchdog module:\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "\n",
    "def terminate_existing_process():\n",
    "    \"\"\"\n",
    "    Terminates any running Streamlit process on the specified port.\n",
    "    \"\"\"\n",
    "    port = \"8501\"\n",
    "    try:\n",
    "        # Find processes using the specified port\n",
    "        result = subprocess.run(\n",
    "            [\"lsof\", \"-i\", f\":{port}\"], stdout=subprocess.PIPE, text=True\n",
    "        )\n",
    "        lines = result.stdout.splitlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            if \"LISTEN\" in line:\n",
    "                parts = line.split()\n",
    "                pid = int(parts[1])  # The second column contains the process ID\n",
    "                os.kill(pid, signal.SIGKILL)  # Terminate the process\n",
    "                print(f\"Terminated process with PID {pid} on port {port}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error terminating process: {e}\")\n",
    "\n",
    "def run_app():\n",
    "    \"\"\"\n",
    "    Runs the Streamlit app on the specified port.\n",
    "    \"\"\"\n",
    "    terminate_existing_process()  # Ensure no old processes are running\n",
    "    process = subprocess.Popen(\n",
    "        ['streamlit', 'run', 'plan3.py', '--server.port', '8501'],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        universal_newlines=True\n",
    "    )\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "threading.Thread(target=run_app).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
